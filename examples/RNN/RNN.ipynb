{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the example of MARBLE applied to low-rank RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import MARBLE\n",
    "from MARBLE import geometry, plotting\n",
    "from RNN_scripts import dms, helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by downloading some intermediate data to reproduce results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download datasets\n",
    "!mkdir data\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963161 -O data/dms_rank2_500.pt\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963162 -O data/dms_rank2_500_2.pt\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963166 -O data/dms_rank2_500_sampled_1.pt \n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963165 -O data/dms_rank2_500_sampled_2.pt \n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963163 -O data/RNN_trajectories11.pkl \n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963164 -O data/RNN_trajectories12.pkl \n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/6963158 -O data/RNN_trajectories2.pkl\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7062817 -O data/data_solution_1.pkl\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7062816 -O data/data_all_solutions.pkl\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7509026 -O data/best_model_20231023-113502.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7509027 -O data/best_model_20231023-115754.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load two RNN solutions pretrained on the DMS task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, net1 = helpers.load_network('data/dms_rank2_500.pt')\n",
    "_, net2 = helpers.load_network('data/dms_rank2_500_2.pt')\n",
    "\n",
    "helpers.plot_coefficients(net1)\n",
    "helpers.plot_coefficients(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display input/output trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dms.stimulus1_duration_min = 500\n",
    "dms.stimulus1_duration_max = 500\n",
    "dms.delay_duration_min = 1000\n",
    "dms.delay_duration_max = 1000\n",
    "dms.stimulus2_duration_min = 500\n",
    "dms.stimulus2_duration_max = 500\n",
    "dms.decision_duration = 200\n",
    "dms.setup()\n",
    "\n",
    "x1 = dms.generate_dms_data(1, type='A-A')[0]\n",
    "x2 = dms.generate_dms_data(1, type='B-A')[0]\n",
    "outp1, traj1 = net1.forward(x1)\n",
    "outp2, traj2 = net1.forward(x2)\n",
    "x1, x2 = x1.squeeze().numpy(), x2.squeeze().numpy()\n",
    "outp1 = outp1.detach().squeeze().numpy()\n",
    "outp2 = outp2.detach().squeeze().numpy()\n",
    "\n",
    "def time_mapping(t):\n",
    "    return t * dms.deltaT / 1000\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "ax.plot(time_mapping(np.arange(x1.shape[0])), x1[:, 0], c='#65BADA', zorder=30, lw=2)\n",
    "ax.plot(time_mapping(np.arange(x1.shape[0])), x2[:, 0], c='#C82E6B', zorder=30, lw=2)\n",
    "ax.plot([0, 0.2], [-.25, -.25], c='gray', lw=4)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(time_mapping(np.arange(outp1.shape[0])), outp1, color='#65BADA', zorder=30, lw=2)\n",
    "ax.plot(time_mapping(np.arange(outp1.shape[0])), outp2, color='#C82E6B', zorder=30, lw=2)\n",
    "ax.plot([0, 0.2], [-1.25, -1.25], c='gray', lw=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new network by fitting Gaussian mixture to the connectivity space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, net1_sampled_1 = helpers.sample_network(net1, 'data/dms_rank2_500_sampled_1.pt', seed=0)\n",
    "_, net1_sampled_2 = helpers.sample_network(net1, 'data/dms_rank2_500_sampled_2.pt', seed=1)\n",
    "\n",
    "helpers.plot_coefficients(net1_sampled_1)\n",
    "helpers.plot_coefficients(net1_sampled_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design stimulus conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim1_begin, stim1_end, stim2_begin, stim2_end, decision = 25, 50, 200, 225, 275\n",
    "epochs = [0, stim1_begin, stim1_end, stim2_begin, stim2_end, decision]\n",
    "\n",
    "n_gains=20\n",
    "gain = np.linspace(1, 0, n_gains)\n",
    "    \n",
    "input_data = torch.zeros(n_gains, decision, 2)\n",
    "for i, g in enumerate(gain):\n",
    "    input_data[i, stim1_begin:stim1_end, 0] = g\n",
    "    input_data[i, stim2_begin:stim2_end, 0] = g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below to generate trajectories (slow, if not loading existing file) \n",
    "n_traj=200\n",
    "traj11 = helpers.generate_trajectories(net1_sampled_1, input_data, epochs, n_traj, fname='data/RNN_trajectories11.pkl')\n",
    "traj12 = helpers.generate_trajectories(net1_sampled_2, input_data, epochs, n_traj, fname='data/RNN_trajectories12.pkl')\n",
    "traj2 = helpers.generate_trajectories(net2, input_data, epochs, n_traj, fname='data/RNN_trajectories2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot phase portraits of two different dynamics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_traj=2\n",
    "traj = helpers.generate_trajectories(net1_sampled_1, input_data, epochs, n_traj)\n",
    "helpers.plot_experiment(net1_sampled_1, input_data, traj, epochs, rect=(-6, 6, -4, 4), traj_to_show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_experiment(net2, input_data, traj2, epochs, rect=(-6, 6, -4, 4), traj_to_show=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for g in gain:\n",
    "    _, _, _, x_val, y_val, mask_val = dms.generate_dms_data(10000, gain=g)\n",
    "    loss, acc = dms.test_dms(net1, x_val, y_val, mask_val)\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "plt.plot(gain, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate data and create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient = 15 #clip 15 timesteps\n",
    "pos11, vel11 = helpers.aggregate_data(traj11, epochs, transient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model on network solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./data/data_solution_1.pkl','rb')) #if you're impatient\n",
    "#data = MARBLE.construct_dataset(pos11, features=vel11, graph_type='cknn', k=15, spacing=0.01) # takes 5-10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'best_model_20231023-113502.pth'\n",
    "model = MARBLE.net(data, loadpath='./data/'+model_file)\n",
    "\n",
    "#params = {'epochs': 40, \n",
    "#          'hidden_channels': 64, \n",
    "#          'out_channels': 5,\n",
    "#          'diffusion': False,\n",
    "#          'inner_product_features': False, #geometry-aware for maximal expressivity\n",
    "#          }\n",
    "#model = MARBLE.net(data, params=params)\n",
    "#model.fit(data, outdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.transform(data)\n",
    "data = MARBLE.distribution_distances(data, n_clusters=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster and plot distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram                                                          \n",
    "from scipy.cluster.hierarchy import linkage                                                             \n",
    "from scipy.spatial.distance import squareform   \n",
    "\n",
    "def cluster_matrix(df, distance=False, ax=None):                                                                 \n",
    "    \"\"\"Return sorted labels to cluster a matrix with linkage.                                           \n",
    "                                                                                                        \n",
    "    If distance matrix already set distance=True.                                                       \n",
    "    \"\"\"                                                                                                 \n",
    "                                                                                                        \n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):                                                \n",
    "        _data = df if distance else 1.0 / df                              \n",
    "                                                                                                        \n",
    "    _data[_data > 1e10] = 1000                                                                          \n",
    "    np.fill_diagonal(_data, 0.0)                                                                        \n",
    "    dists = squareform(_data)                                                                           \n",
    "    Z = linkage(dists, \"ward\")                                                                          \n",
    "    labels = np.arange(0, len(df))                                                                     \n",
    "    dn = dendrogram(Z, labels=labels, ax=ax)                                                     \n",
    "    return labels[dn[\"leaves\"]]     \n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "l = cluster_matrix(data.dist, distance=True, ax=plt.gca())\n",
    "plt.xlabel('original labels')\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(np.arange(0, len(data.dist)), l)\n",
    "plt.xlabel('original labels')\n",
    "plt.ylabel('clustered labels')\n",
    "plt.axvline(len(data.dist)/2-0.5, c='r')\n",
    "plt.axvline(3*len(data.dist)/4-0.5, c='r')\n",
    "\n",
    "plt.figure()\n",
    "im = plt.imshow(data.dist)\n",
    "plt.colorbar(im)\n",
    "plt.axhline(len(data.dist)/2-0.5, c='r')\n",
    "plt.axhline(3*len(data.dist)/4-0.5, c='r')\n",
    "plt.axvline(len(data.dist)/2-0.5, c='r')\n",
    "plt.axvline(3*len(data.dist)/4-0.5, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network with solution I and solution II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient = 15 #clip 15 timesteps\n",
    "pos11, vel11 = helpers.aggregate_data(traj11, epochs, transient)\n",
    "pos12, vel12 = helpers.aggregate_data(traj12, epochs, transient)\n",
    "pos2, vel2 = helpers.aggregate_data(traj2, epochs, transient)\n",
    "\n",
    "pos = pos11 + pos12 + pos2\n",
    "vel = vel11 + vel12 + vel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pickle.load(open('./data/data_all_solutions.pkl','rb')) #if you're impatient\n",
    "#data2 = MARBLE.construct_dataset(pos, features=vel, graph_type='cknn', k=15, spacing=0.01) # takes up to 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'best_model_20231023-115754.pth'\n",
    "model2 = MARBLE.net(data, loadpath='./data/'+model_file)\n",
    "\n",
    "#params = {'epochs': 40,\n",
    "#          'order': 2,\n",
    "#          'hidden_channels': 64,\n",
    "#          'out_channels': 5,\n",
    "#          'diffusion': False,\n",
    "#          'inner_product_features': True, #geometry-agnostic as manifolds are differently oriented across networks\n",
    "#         }\n",
    "\n",
    "#model2 = MARBLE.net(data2, params=params)\n",
    "#model2.fit(data2, outdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = model2.transform(data2)\n",
    "data2 = MARBLE.distribution_distances(data2, n_clusters=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(data2.dist) // 6\n",
    "dist = data2.dist[:2 * n,:2 * n]\n",
    "ind = list(range(n,2 * n)) + list(range(3 * n,4 * n)) + list(range(5 * n,6 * n))\n",
    "dist = data2.dist[ind,:][:,ind]\n",
    "im = plt.imshow(dist)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([g for g in gain ])\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot()\n",
    "emb_MDS, _ = geometry.embed(dist, embed_typ = 'MDS')\n",
    "ax = plotting.embedding(emb_MDS[:n], labels, ax=ax, s=30, alpha=1, axes_visible=True)\n",
    "ax = plotting.embedding(emb_MDS[n:2*n], labels, ax=ax, s=30, alpha=1, axes_visible=True, cmap='PuOr')\n",
    "ax = plotting.embedding(emb_MDS[2*n:], labels, ax=ax, s=30, alpha=1, axes_visible=True, cmap='PRGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results with Canonical Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transient = 15 #clip 15 timesteps\n",
    "pos11, vel11 = helpers.aggregate_data(traj11, epochs, transient, pca=False)\n",
    "pos12, vel12 = helpers.aggregate_data(traj12, epochs, transient, pca=False)\n",
    "pos2, vel2 = helpers.aggregate_data(traj2, epochs, transient, pca=False)\n",
    "\n",
    "pos = pos11 + pos12 + pos2\n",
    "vel = vel11 + vel12 + vel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_comp = 3\n",
    "\n",
    "scaler = StandardScaler() \n",
    "s = data2._slice_dict[\"x\"]\n",
    "ns = len(s)-1\n",
    "cca = CCA(scale=False, n_components=n_comp) #define CCA\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "dist_CCA = np.zeros([ns,ns])\n",
    "\n",
    "pos_transform = []\n",
    "for p in tqdm(pos):\n",
    "    p = scaler.fit_transform(p)\n",
    "    p = pca.fit_transform(p.T).T\n",
    "    pos_transform.append(p)\n",
    "    \n",
    "for i in tqdm(range(ns)):\n",
    "    for j in range(ns):\n",
    "    \n",
    "        u = pos_transform[i]\n",
    "        v = pos_transform[j]\n",
    "          \n",
    "        cca.fit(u, v) #fit our scaled data\n",
    "        u, v = cca.transform(u, v)\n",
    "\n",
    "        comp_corr = [np.corrcoef(u[:, i], v[:, i])[1][0] for i in range(n_comp)]\n",
    "        comp_corr = np.array(comp_corr)\n",
    "        dist_CCA[i,j] = comp_corr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as CCA measures the change in loadings between principal axes across datasets, it does not pick up dynamical changes because they all relate to within-plane variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imshow(dist_CCA)\n",
    "plt.colorbar(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
