{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3429d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from DE_library import simulate_ODE, simulate_trajectories\n",
    "import matplotlib.pyplot as plt\n",
    "from example_utils import reject_outliers, initial_conditions, plot_phase_portrait\n",
    "\n",
    "from MARBLE import utils, geometry, net, plotting, postprocessing, compare_attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4ddd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_system(mu, X0, t):\n",
    "    p, v = simulate_trajectories('vanderpol', X0, t, par = {'mu': mu})\n",
    "    pos, vel = [], []\n",
    "    for p_, v_ in zip(p,v):\n",
    "        ind = reject_outliers(p_, v_)\n",
    "        pos.append(p_[ind])\n",
    "        vel.append(v_[ind])\n",
    "        \n",
    "    return pos, vel\n",
    "\n",
    "def parabola(X, Y, alpha):\n",
    "    Z = -(alpha*X)**2 -(alpha*Y)**2\n",
    "    \n",
    "    return np.column_stack([X.flatten(), Y.flatten(), Z.flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcb700",
   "metadata": {},
   "source": [
    "# For initial conditions, sample a rectangle uniformly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938be9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, t1, dt = 0, 3, 0.5\n",
    "t = np.arange(t0, t1, dt)\n",
    "n = 100\n",
    "area = [[-3,-3],[3,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63dae69",
   "metadata": {},
   "source": [
    "# Geneate phase portraits from random initial conditions while varying $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2afd125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/lts2/gosztolai/miniconda3/envs/MARBLE/lib/python3.9/site-packages/scipy/integrate/_odepack_py.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    }
   ],
   "source": [
    "n_steps=10\n",
    "beta1 = np.hstack((np.linspace(-.5,.5,n_steps)))\n",
    "\n",
    "pos, vel = [], []\n",
    "X0_range = initial_conditions(n, len(beta1), area)\n",
    "for i, b1 in enumerate(beta1):\n",
    "    p, v = simulate_system(b1, X0_range[i], t)\n",
    "            \n",
    "    pos.append(np.vstack(p))\n",
    "    vel.append(np.vstack(v))\n",
    "    \n",
    "#embed on cone\n",
    "alpha = 0.1\n",
    "for i, (p, v) in enumerate(zip(pos, vel)):\n",
    "    end_point = p + v\n",
    "    new_endpoint = parabola(end_point[:,0], end_point[:,1], alpha)\n",
    "    pos[i] = parabola(p[:,0], p[:,1], alpha)\n",
    "    vel[i] = new_endpoint - pos[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b73bb",
   "metadata": {},
   "source": [
    "# Plot vector fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84bbf7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Embedding dimension: 3\n",
      "---- Signal dimension: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing gauges...: 100%|██████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fraction of variance explained:  tensor([0.5771, 1.0000, 1.0000])\n",
      "\n",
      "---- Manifold dimension: 2\n",
      "\n",
      "Manifold dimension can decrease with more data. Try smaller values of stop_crit                 before settling on a value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing connections...: 100%|██████████████████████████████████████████████████████████████████████████| 14553/14553 [00:18<00:00, 770.02it/s]\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "\n",
    "data = utils.construct_dataset(pos, features=vel, graph_type='cknn', k=k, stop_crit=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [r'$\\beta$ = {:0.2f}'.format(b) for b in beta1]\n",
    "\n",
    "#plotting.fields(data, col=4, alpha=0.3, scale=10)\n",
    "axes = plotting.fields(data, col=4, alpha=0.5, width=7, scale=2, titles=titles, view=[50,20])\n",
    "\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "x = y = np.arange(-3.0, 3.0, 0.05)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "xyz = np.array(parabola(np.ravel(X), np.ravel(Y), alpha))\n",
    "ls = LightSource(azdeg=30,altdeg=30)\n",
    "rgb = ls.shade(xyz[:,2].reshape(X.shape)-0.1, plt.cm.gray)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot_surface(xyz[:,0].reshape(X.shape), xyz[:,1].reshape(X.shape), xyz[:,2].reshape(X.shape), \n",
    "                color='gray', \n",
    "                shade=True,\n",
    "                lightsource=ls,\n",
    "                facecolors=rgb\n",
    "               )\n",
    "plt.savefig('../results/parabolas.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e68335",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7752709",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 100\n",
      "order : 2\n",
      "hidden_channels : 16\n",
      "out_channels : 3\n",
      "inner_product_features : True\n",
      "autoencoder : False\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "diffusion : False\n",
      "frac_sampled_nb : -1\n",
      "dropout : 0.0\n",
      "n_lin_layers : 2\n",
      "bias : True\n",
      "vec_norm : False\n",
      "batch_norm : None\n",
      "seed : 0\n",
      "processes : 1\n",
      "dim_signal : 3\n",
      "dim_emb : 3\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  13\n",
      "---- Total number of parameters:  394\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "Epoch: 1, Training loss: 1.3828, Validation loss: 1.3810, lr: 0.0100 *\n",
      "Epoch: 2, Training loss: 1.3806, Validation loss: 1.3795, lr: 0.0100 *\n",
      "Epoch: 3, Training loss: 1.3771, Validation loss: 1.3762, lr: 0.0100 *\n",
      "Epoch: 4, Training loss: 1.3742, Validation loss: 1.3692, lr: 0.0100 *\n",
      "Epoch: 5, Training loss: 1.3649, Validation loss: 1.3606, lr: 0.0100 *\n",
      "Epoch: 6, Training loss: 1.3518, Validation loss: 1.3581, lr: 0.0100 *\n",
      "Epoch: 7, Training loss: 1.3187, Validation loss: 1.2772, lr: 0.0100 *\n",
      "Epoch: 8, Training loss: 1.2787, Validation loss: 1.2154, lr: 0.0100 *\n",
      "Epoch: 9, Training loss: 1.2163, Validation loss: 1.2168, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.2114, Validation loss: 1.1452, lr: 0.0100 *\n",
      "Epoch: 11, Training loss: 1.1985, Validation loss: 1.2593, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.1869, Validation loss: 1.1487, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.1923, Validation loss: 1.1847, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.1799, Validation loss: 1.1503, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.1482, Validation loss: 1.2065, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.1542, Validation loss: 1.1406, lr: 0.0100 *\n",
      "Epoch: 17, Training loss: 1.1339, Validation loss: 1.1686, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.1272, Validation loss: 1.1688, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.1130, Validation loss: 1.1916, lr: 0.0100\n",
      "Epoch: 20, Training loss: 1.1508, Validation loss: 1.1104, lr: 0.0100 *\n",
      "Epoch: 21, Training loss: 1.1341, Validation loss: 1.1792, lr: 0.0100\n",
      "Epoch: 22, Training loss: 1.1128, Validation loss: 1.1144, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.1232, Validation loss: 1.1986, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.1212, Validation loss: 1.1688, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.1098, Validation loss: 1.0726, lr: 0.0100 *\n",
      "Epoch: 26, Training loss: 1.1158, Validation loss: 1.0457, lr: 0.0100 *\n",
      "Epoch: 27, Training loss: 1.0925, Validation loss: 1.0838, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.0969, Validation loss: 1.1257, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.0689, Validation loss: 1.1260, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.0707, Validation loss: 1.0971, lr: 0.0100\n",
      "Epoch: 31, Training loss: 1.1144, Validation loss: 1.1470, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.1076, Validation loss: 1.1248, lr: 0.0100\n",
      "Epoch: 33, Training loss: 1.0930, Validation loss: 1.0729, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.0711, Validation loss: 1.1073, lr: 0.0100\n",
      "Epoch: 35, Training loss: 1.1013, Validation loss: 1.0460, lr: 0.0100\n",
      "Epoch: 36, Training loss: 1.0926, Validation loss: 1.1859, lr: 0.0100\n",
      "Epoch: 37, Training loss: 1.0992, Validation loss: 1.1438, lr: 0.0100\n",
      "Epoch: 38, Training loss: 1.0918, Validation loss: 1.1392, lr: 0.0100\n",
      "Epoch: 39, Training loss: 1.0481, Validation loss: 1.0876, lr: 0.0100\n",
      "Epoch: 40, Training loss: 1.0803, Validation loss: 1.1467, lr: 0.0100\n",
      "Epoch: 41, Training loss: 1.0766, Validation loss: 1.0621, lr: 0.0100\n",
      "Epoch: 42, Training loss: 1.1067, Validation loss: 1.0529, lr: 0.0100\n",
      "Epoch: 43, Training loss: 1.0768, Validation loss: 1.0329, lr: 0.0100 *\n",
      "Epoch: 44, Training loss: 1.0999, Validation loss: 1.0754, lr: 0.0100\n",
      "Epoch: 45, Training loss: 1.0947, Validation loss: 1.1262, lr: 0.0100\n",
      "Epoch: 46, Training loss: 1.0543, Validation loss: 1.0221, lr: 0.0100 *\n",
      "Epoch: 47, Training loss: 1.0790, Validation loss: 1.0858, lr: 0.0100\n",
      "Epoch: 48, Training loss: 1.1029, Validation loss: 1.0810, lr: 0.0100\n",
      "Epoch: 49, Training loss: 1.0777, Validation loss: 1.0589, lr: 0.0100\n",
      "Epoch: 50, Training loss: 1.0543, Validation loss: 1.1465, lr: 0.0010\n",
      "Epoch: 51, Training loss: 1.0808, Validation loss: 1.0283, lr: 0.0010\n",
      "Epoch: 52, Training loss: 1.0505, Validation loss: 1.2218, lr: 0.0010\n",
      "Epoch: 53, Training loss: 1.0816, Validation loss: 1.0860, lr: 0.0010\n",
      "Epoch: 54, Training loss: 1.0617, Validation loss: 1.1090, lr: 0.0010\n",
      "Epoch: 55, Training loss: 1.0825, Validation loss: 1.1688, lr: 0.0010\n",
      "Epoch: 56, Training loss: 1.1030, Validation loss: 1.1741, lr: 0.0010\n",
      "Epoch: 57, Training loss: 1.0656, Validation loss: 1.0167, lr: 0.0010 *\n",
      "Epoch: 58, Training loss: 1.0772, Validation loss: 1.0860, lr: 0.0010\n",
      "Epoch: 59, Training loss: 1.0764, Validation loss: 1.0936, lr: 0.0010\n",
      "Epoch: 60, Training loss: 1.0887, Validation loss: 1.0815, lr: 0.0010\n",
      "Epoch: 61, Training loss: 1.0765, Validation loss: 1.0929, lr: 0.0001\n",
      "Epoch: 62, Training loss: 1.0809, Validation loss: 1.1079, lr: 0.0001\n",
      "Epoch: 63, Training loss: 1.0714, Validation loss: 0.9869, lr: 0.0001 *\n",
      "Epoch: 64, Training loss: 1.0721, Validation loss: 1.0625, lr: 0.0001\n",
      "Epoch: 65, Training loss: 1.0881, Validation loss: 1.0723, lr: 0.0001\n",
      "Epoch: 66, Training loss: 1.0633, Validation loss: 1.0967, lr: 0.0001\n",
      "Epoch: 67, Training loss: 1.0728, Validation loss: 1.1527, lr: 0.0001\n",
      "Epoch: 68, Training loss: 1.0914, Validation loss: 1.0173, lr: 0.0001\n",
      "Epoch: 69, Training loss: 1.0837, Validation loss: 1.0313, lr: 0.0001\n",
      "Epoch: 70, Training loss: 1.0651, Validation loss: 1.0428, lr: 0.0001\n",
      "Epoch: 71, Training loss: 1.0747, Validation loss: 0.9840, lr: 0.0001 *\n",
      "Epoch: 72, Training loss: 1.0764, Validation loss: 1.0880, lr: 0.0000\n",
      "Epoch: 73, Training loss: 1.0795, Validation loss: 1.0484, lr: 0.0000\n",
      "Epoch: 74, Training loss: 1.0446, Validation loss: 1.1320, lr: 0.0000\n",
      "Epoch: 75, Training loss: 1.0741, Validation loss: 1.0345, lr: 0.0000\n",
      "Epoch: 76, Training loss: 1.0798, Validation loss: 1.0282, lr: 0.0000\n",
      "Epoch: 77, Training loss: 1.0887, Validation loss: 1.0761, lr: 0.0000\n",
      "Epoch: 78, Training loss: 1.0660, Validation loss: 1.1486, lr: 0.0000\n",
      "Epoch: 79, Training loss: 1.0522, Validation loss: 1.0616, lr: 0.0000\n",
      "Epoch: 80, Training loss: 1.0817, Validation loss: 1.0979, lr: 0.0000\n",
      "Epoch: 81, Training loss: 1.0901, Validation loss: 1.1723, lr: 0.0000\n",
      "Epoch: 82, Training loss: 1.0716, Validation loss: 1.1038, lr: 0.0000\n",
      "Epoch: 83, Training loss: 1.0675, Validation loss: 1.1749, lr: 0.0000\n",
      "Epoch: 84, Training loss: 1.0861, Validation loss: 1.0843, lr: 0.0000\n",
      "Epoch: 85, Training loss: 1.0620, Validation loss: 1.0325, lr: 0.0000\n",
      "Epoch: 86, Training loss: 1.0985, Validation loss: 0.9690, lr: 0.0000 *\n",
      "Epoch: 87, Training loss: 1.0937, Validation loss: 1.0121, lr: 0.0000\n",
      "Epoch: 88, Training loss: 1.0714, Validation loss: 1.1168, lr: 0.0000\n",
      "Epoch: 89, Training loss: 1.0485, Validation loss: 1.0055, lr: 0.0000\n",
      "Epoch: 90, Training loss: 1.1159, Validation loss: 1.2480, lr: 0.0000\n",
      "Epoch: 91, Training loss: 1.0722, Validation loss: 1.0814, lr: 0.0000\n",
      "Epoch: 92, Training loss: 1.0708, Validation loss: 1.0092, lr: 0.0000\n",
      "Epoch: 93, Training loss: 1.0795, Validation loss: 1.0429, lr: 0.0000\n",
      "Epoch: 94, Training loss: 1.0677, Validation loss: 1.0612, lr: 0.0000\n",
      "Epoch: 95, Training loss: 1.0530, Validation loss: 1.0983, lr: 0.0000\n",
      "Epoch: 96, Training loss: 1.0863, Validation loss: 1.0071, lr: 0.0000\n",
      "Epoch: 97, Training loss: 1.0715, Validation loss: 1.0891, lr: 0.0000\n",
      "Epoch: 98, Training loss: 1.0426, Validation loss: 1.0291, lr: 0.0000\n",
      "Epoch: 99, Training loss: 1.0432, Validation loss: 1.0975, lr: 0.0000\n",
      "Epoch: 100, Training loss: 1.0801, Validation loss: 0.9759, lr: 0.0000\n",
      "Final test loss: 1.0740\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "par = {'epochs': 100, #optimisation epochs\n",
    "       'order': 2, #order of derivatives\n",
    "       'hidden_channels': 16, #number of internal dimensions in MLP\n",
    "       'out_channels': 3,\n",
    "       'inner_product_features': True,\n",
    "       'autoencoder': False,\n",
    "      }\n",
    "\n",
    "model = net(data, **par)\n",
    "model.run_training(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818b71e",
   "metadata": {},
   "source": [
    "# Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f67159d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed umap embedding on embedded results.\n",
      "Performed MDS embedding on embedded results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = model.evaluate(data)\n",
    "n_clusters=20\n",
    "data = postprocessing(data, n_clusters=n_clusters)\n",
    "\n",
    "emb_MDS, _ = geometry.embed(data.dist, embed_typ = 'MDS')\n",
    "plotting.embedding(emb_MDS, beta1, s=30, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314fb06",
   "metadata": {},
   "source": [
    "# Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12592529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f506c6b77c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce2f03",
   "metadata": {},
   "source": [
    "# Cluster and visualise embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [r'$\\beta$ = {:0.2f}'.format(b) for b in beta1]\n",
    "plotting.embedding(data.emb_2d, data.y.numpy(), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attractors(data, (4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83dd7a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_clusters=[2,4,6,8]\n",
    "fig, ax = plt.subplots(len(n_clusters),4, figsize=(10,10))\n",
    "slices=data._slice_dict['x']\n",
    "\n",
    "def plot_embedding(data, ax, slices, i, n_clusters=2):\n",
    "    s = range(slices[i], slices[i+1])\n",
    "    clusters = geometry.cluster(data.emb_2d, cluster_typ='kmeans', n_clusters=n_clusters, seed=0)\n",
    "    plotting.embedding(data.emb_2d[s], clusters['labels'][s], ax=ax[0])\n",
    "    plot_phase_portrait(data.pos[s], data.x[s], ax[1], node_feature=clusters['labels'][s])\n",
    "\n",
    "snapshot=4\n",
    "for i, n in enumerate(n_clusters):\n",
    "    plot_embedding(data, ax[:,:2][i], slices, snapshot, n_clusters=n)\n",
    "    \n",
    "snapshot=5\n",
    "for i, n in enumerate(n_clusters):\n",
    "    plot_embedding(data, ax[:,2:][i], slices, snapshot, n_clusters=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59cd5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
