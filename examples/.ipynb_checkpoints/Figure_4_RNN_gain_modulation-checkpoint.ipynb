{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3429d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from DE_library import simulate_ODE, simulate_trajectories\n",
    "import matplotlib.pyplot as plt\n",
    "from example_utils import reject_outliers, initial_conditions, plot_phase_portrait\n",
    "\n",
    "from MARBLE import utils, geometry, net, plotting, postprocessing, compare_attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4ddd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_system(mu, X0, t):\n",
    "    p, v = simulate_trajectories('vanderpol', X0, t, par = {'mu': mu})\n",
    "    pos, vel = [], []\n",
    "    for p_, v_ in zip(p,v):\n",
    "        ind = reject_outliers(p_, v_)\n",
    "        pos.append(p_[ind])\n",
    "        vel.append(v_[ind])\n",
    "        \n",
    "    return pos, vel\n",
    "\n",
    "def parabola(X, Y, alpha=0.05):\n",
    "    Z = -(alpha*X)**2 -(alpha*Y)**2\n",
    "    \n",
    "    return np.column_stack([X.flatten(), Y.flatten(), Z.flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcb700",
   "metadata": {},
   "source": [
    "# For initial conditions, sample a rectangle uniformly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938be9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, t1, dt = 0, 3, 0.5\n",
    "t = np.arange(t0, t1, dt)\n",
    "n = 100\n",
    "area = [[-3,-3],[3,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63dae69",
   "metadata": {},
   "source": [
    "# Geneate phase portraits from random initial conditions while varying $\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afd125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/scratch/lts2/gosztolai/miniconda3/envs/MARBLE/lib/python3.9/site-packages/scipy/integrate/_odepack_py.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n"
     ]
    }
   ],
   "source": [
    "n_steps=10\n",
    "beta1 = np.hstack((np.linspace(-.5,.5,n_steps)))\n",
    "\n",
    "pos, vel = [], []\n",
    "X0_range = initial_conditions(n, len(beta1), area)\n",
    "for i, b1 in enumerate(beta1):\n",
    "    p, v = simulate_system(b1, X0_range[i], t)\n",
    "            \n",
    "    pos.append(np.vstack(p))\n",
    "    vel.append(np.vstack(v))\n",
    "    \n",
    "#embed on parabola\n",
    "for i, (p, v) in enumerate(zip(pos, vel)):\n",
    "    end_point = p + v\n",
    "    new_endpoint = parabola(end_point[:,0], end_point[:,1])\n",
    "    pos[i] = parabola(p[:,0], p[:,1])\n",
    "    vel[i] = new_endpoint - pos[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b73bb",
   "metadata": {},
   "source": [
    "# Plot vector fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bbf7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Embedding dimension: 3\n",
      "---- Signal dimension: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing gauges...: 100%|██████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fraction of variance explained:  tensor([0.5590, 1.0000, 1.0000])\n",
      "\n",
      "---- Manifold dimension: 2\n",
      "\n",
      "Manifold dimension can decrease with more data. Try smaller values of stop_crit                 before settling on a value\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing connections...: 100%|██████████████████████████████████████████████████████████████████████████| 43912/43912 [00:49<00:00, 880.97it/s]\n"
     ]
    }
   ],
   "source": [
    "k=15\n",
    "\n",
    "data = utils.construct_dataset(pos, features=vel, graph_type='cknn', k=k, stop_crit=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa06e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = [r'$\\beta$ = {:0.2f}'.format(b) for b in beta1]\n",
    "\n",
    "#plotting.fields(data, col=4, alpha=0.3, scale=10)\n",
    "axes = plotting.fields(data, col=4, alpha=1, width=7, scale=2, titles=titles, view=[70,20])\n",
    "\n",
    "from matplotlib.colors import LightSource\n",
    "\n",
    "x = y = np.arange(-3.0, 3.0, 0.05)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "xyz = np.array(parabola(np.ravel(X), np.ravel(Y)))\n",
    "ls = LightSource(azdeg=30,altdeg=30)\n",
    "rgb = ls.shade(xyz[:,2].reshape(X.shape)-0.1, plt.cm.gray)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot_surface(xyz[:,0].reshape(X.shape), xyz[:,1].reshape(X.shape), xyz[:,2].reshape(X.shape)-0.02, \n",
    "                color='gray', \n",
    "                shade=True,\n",
    "                lightsource=ls,\n",
    "                facecolors=rgb\n",
    "               )\n",
    "#plt.savefig('../results/parabolas.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e68335",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7752709",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Settings: \n",
      "\n",
      "epochs : 100\n",
      "order : 2\n",
      "hidden_channels : 16\n",
      "out_channels : 3\n",
      "inner_product_features : True\n",
      "batch_size : 64\n",
      "lr : 0.01\n",
      "momentum : 0.9\n",
      "autoencoder : False\n",
      "diffusion : False\n",
      "frac_sampled_nb : -1\n",
      "dropout : 0.0\n",
      "n_lin_layers : 2\n",
      "bias : True\n",
      "vec_norm : False\n",
      "batch_norm : None\n",
      "seed : 0\n",
      "processes : 1\n",
      "dim_signal : 3\n",
      "dim_emb : 3\n",
      "n_sampled_nb : -1\n",
      "\n",
      "---- Number of features to pass to the MLP:  13\n",
      "---- Total number of parameters:  394\n",
      "\n",
      "---- Training network ...\n",
      "\n",
      "Epoch: 1, Training loss: 1.3856, Validation loss: 1.3831, lr: 0.0100 *\n",
      "Epoch: 2, Training loss: 1.3831, Validation loss: 1.3831, lr: 0.0100 *\n",
      "Epoch: 3, Training loss: 1.3818, Validation loss: 1.3798, lr: 0.0100 *\n",
      "Epoch: 4, Training loss: 1.3812, Validation loss: 1.3792, lr: 0.0100 *\n",
      "Epoch: 5, Training loss: 1.3782, Validation loss: 1.3731, lr: 0.0100 *\n",
      "Epoch: 6, Training loss: 1.3739, Validation loss: 1.3704, lr: 0.0100 *\n",
      "Epoch: 7, Training loss: 1.3677, Validation loss: 1.3646, lr: 0.0100 *\n",
      "Epoch: 8, Training loss: 1.3622, Validation loss: 1.3500, lr: 0.0100 *\n",
      "Epoch: 9, Training loss: 1.3561, Validation loss: 1.3646, lr: 0.0100\n",
      "Epoch: 10, Training loss: 1.3533, Validation loss: 1.3288, lr: 0.0100 *\n",
      "Epoch: 11, Training loss: 1.3474, Validation loss: 1.3378, lr: 0.0100\n",
      "Epoch: 12, Training loss: 1.3425, Validation loss: 1.3463, lr: 0.0100\n",
      "Epoch: 13, Training loss: 1.3389, Validation loss: 1.3442, lr: 0.0100\n",
      "Epoch: 14, Training loss: 1.3396, Validation loss: 1.3349, lr: 0.0100\n",
      "Epoch: 15, Training loss: 1.3211, Validation loss: 1.3576, lr: 0.0100\n",
      "Epoch: 16, Training loss: 1.3211, Validation loss: 1.2971, lr: 0.0100 *\n",
      "Epoch: 17, Training loss: 1.3122, Validation loss: 1.3040, lr: 0.0100\n",
      "Epoch: 18, Training loss: 1.3056, Validation loss: 1.3224, lr: 0.0100\n",
      "Epoch: 19, Training loss: 1.3225, Validation loss: 1.2907, lr: 0.0100 *\n",
      "Epoch: 20, Training loss: 1.3166, Validation loss: 1.2917, lr: 0.0100\n",
      "Epoch: 21, Training loss: 1.3088, Validation loss: 1.2687, lr: 0.0100 *\n",
      "Epoch: 22, Training loss: 1.2956, Validation loss: 1.2925, lr: 0.0100\n",
      "Epoch: 23, Training loss: 1.2959, Validation loss: 1.2834, lr: 0.0100\n",
      "Epoch: 24, Training loss: 1.2952, Validation loss: 1.2702, lr: 0.0100\n",
      "Epoch: 25, Training loss: 1.2856, Validation loss: 1.2894, lr: 0.0100\n",
      "Epoch: 26, Training loss: 1.2847, Validation loss: 1.2934, lr: 0.0100\n",
      "Epoch: 27, Training loss: 1.2883, Validation loss: 1.3009, lr: 0.0100\n",
      "Epoch: 28, Training loss: 1.2765, Validation loss: 1.2732, lr: 0.0100\n",
      "Epoch: 29, Training loss: 1.2803, Validation loss: 1.2718, lr: 0.0100\n",
      "Epoch: 30, Training loss: 1.2600, Validation loss: 1.2504, lr: 0.0100 *\n",
      "Epoch: 31, Training loss: 1.2718, Validation loss: 1.2579, lr: 0.0100\n",
      "Epoch: 32, Training loss: 1.2760, Validation loss: 1.2383, lr: 0.0100 *\n",
      "Epoch: 33, Training loss: 1.2639, Validation loss: 1.2551, lr: 0.0100\n",
      "Epoch: 34, Training loss: 1.2603, Validation loss: 1.3261, lr: 0.0100\n",
      "Epoch: 35, Training loss: 1.2673, Validation loss: 1.2661, lr: 0.0100\n",
      "Epoch: 36, Training loss: 1.2597, Validation loss: 1.2436, lr: 0.0100\n",
      "Epoch: 37, Training loss: 1.2543, Validation loss: 1.2437, lr: 0.0100\n",
      "Epoch: 38, Training loss: 1.2456, Validation loss: 1.2365, lr: 0.0100 *\n",
      "Epoch: 39, Training loss: 1.2147, Validation loss: 1.2165, lr: 0.0100 *\n",
      "Epoch: 40, Training loss: 1.2381, Validation loss: 1.2445, lr: 0.0100\n",
      "Epoch: 41, Training loss: 1.2174, Validation loss: 1.2019, lr: 0.0100 *\n",
      "Epoch: 42, Training loss: 1.1911, Validation loss: 1.2466, lr: 0.0100\n",
      "Epoch: 43, Training loss: 1.1809, Validation loss: 1.2173, lr: 0.0100\n",
      "Epoch: 44, Training loss: 1.1637, Validation loss: 1.1333, lr: 0.0100 *\n",
      "Epoch: 45, Training loss: 1.1585, Validation loss: 1.2050, lr: 0.0100\n",
      "Epoch: 46, Training loss: 1.1620, Validation loss: 1.1889, lr: 0.0100\n",
      "Epoch: 47, Training loss: 1.1660, Validation loss: 1.2184, lr: 0.0100\n",
      "Epoch: 48, Training loss: 1.1593, Validation loss: 1.1824, lr: 0.0100\n",
      "Epoch: 49, Training loss: 1.1555, Validation loss: 1.1330, lr: 0.0100 *\n",
      "Epoch: 50, Training loss: 1.1659, Validation loss: 1.2008, lr: 0.0100\n",
      "Epoch: 51, Training loss: 1.1538, Validation loss: 1.1207, lr: 0.0100 *\n",
      "Epoch: 52, Training loss: 1.1405, Validation loss: 1.1443, lr: 0.0100\n",
      "Epoch: 53, Training loss: 1.1582, Validation loss: 1.1382, lr: 0.0100\n",
      "Epoch: 54, Training loss: 1.1460, Validation loss: 1.1799, lr: 0.0100\n",
      "Epoch: 55, Training loss: 1.1409, Validation loss: 1.1053, lr: 0.0100 *\n",
      "Epoch: 56, Training loss: 1.1336, Validation loss: 1.1833, lr: 0.0100\n",
      "Epoch: 57, Training loss: 1.1298, Validation loss: 1.2038, lr: 0.0100\n",
      "Epoch: 58, Training loss: 1.1430, Validation loss: 1.1653, lr: 0.0100\n",
      "Epoch: 59, Training loss: 1.1253, Validation loss: 1.1550, lr: 0.0100\n",
      "Epoch: 60, Training loss: 1.1382, Validation loss: 1.1769, lr: 0.0100\n",
      "Epoch: 61, Training loss: 1.1518, Validation loss: 1.1582, lr: 0.0100\n",
      "Epoch: 62, Training loss: 1.1457, Validation loss: 1.2077, lr: 0.0100\n",
      "Epoch: 63, Training loss: 1.1263, Validation loss: 1.1243, lr: 0.0100\n",
      "Epoch: 64, Training loss: 1.1314, Validation loss: 1.1817, lr: 0.0100\n",
      "Epoch: 65, Training loss: 1.1163, Validation loss: 1.1193, lr: 0.0100\n",
      "Epoch: 66, Training loss: 1.1435, Validation loss: 1.0929, lr: 0.0100 *\n",
      "Epoch: 67, Training loss: 1.1443, Validation loss: 1.1874, lr: 0.0100\n",
      "Epoch: 68, Training loss: 1.1470, Validation loss: 1.1880, lr: 0.0100\n",
      "Epoch: 69, Training loss: 1.1368, Validation loss: 1.1149, lr: 0.0100\n",
      "Epoch: 70, Training loss: 1.1496, Validation loss: 1.1497, lr: 0.0100\n",
      "Epoch: 71, Training loss: 1.1301, Validation loss: 1.1360, lr: 0.0100\n",
      "Epoch: 72, Training loss: 1.1211, Validation loss: 1.1546, lr: 0.0100\n",
      "Epoch: 73, Training loss: 1.1377, Validation loss: 1.1591, lr: 0.0100\n",
      "Epoch: 74, Training loss: 1.1253, Validation loss: 1.2216, lr: 0.0100\n",
      "Epoch: 75, Training loss: 1.1340, Validation loss: 1.1463, lr: 0.0100\n",
      "Epoch: 76, Training loss: 1.1248, Validation loss: 1.1261, lr: 0.0010\n",
      "Epoch: 77, Training loss: 1.1362, Validation loss: 1.1854, lr: 0.0010\n",
      "Epoch: 78, Training loss: 1.1345, Validation loss: 1.1285, lr: 0.0010\n",
      "Epoch: 79, Training loss: 1.1451, Validation loss: 1.1445, lr: 0.0010\n",
      "Epoch: 80, Training loss: 1.1085, Validation loss: 1.1338, lr: 0.0010\n",
      "Epoch: 81, Training loss: 1.1220, Validation loss: 1.1843, lr: 0.0010\n",
      "Epoch: 82, Training loss: 1.1329, Validation loss: 1.1133, lr: 0.0010\n",
      "Epoch: 83, Training loss: 1.1347, Validation loss: 1.1669, lr: 0.0010\n",
      "Epoch: 84, Training loss: 1.1152, Validation loss: 1.1747, lr: 0.0010\n",
      "Epoch: 85, Training loss: 1.1299, Validation loss: 1.1626, lr: 0.0010\n",
      "Epoch: 86, Training loss: 1.1249, Validation loss: 1.2002, lr: 0.0010\n",
      "Epoch: 87, Training loss: 1.1360, Validation loss: 1.1890, lr: 0.0010\n",
      "Epoch: 88, Training loss: 1.1200, Validation loss: 1.1636, lr: 0.0010\n",
      "Epoch: 89, Training loss: 1.1123, Validation loss: 1.1261, lr: 0.0010\n",
      "Epoch: 90, Training loss: 1.1407, Validation loss: 1.1396, lr: 0.0010\n",
      "Epoch: 91, Training loss: 1.1085, Validation loss: 1.1436, lr: 0.0001\n",
      "Epoch: 92, Training loss: 1.1076, Validation loss: 1.1556, lr: 0.0001\n",
      "Epoch: 93, Training loss: 1.1162, Validation loss: 1.1772, lr: 0.0001\n",
      "Epoch: 94, Training loss: 1.1217, Validation loss: 1.1306, lr: 0.0001\n",
      "Epoch: 95, Training loss: 1.1376, Validation loss: 1.1197, lr: 0.0001\n",
      "Epoch: 96, Training loss: 1.1246, Validation loss: 1.1249, lr: 0.0001\n",
      "Epoch: 97, Training loss: 1.1036, Validation loss: 1.0588, lr: 0.0001 *\n",
      "Epoch: 98, Training loss: 1.1196, Validation loss: 1.1462, lr: 0.0001\n",
      "Epoch: 99, Training loss: 1.1262, Validation loss: 1.1476, lr: 0.0001\n",
      "Epoch: 100, Training loss: 1.1290, Validation loss: 1.0965, lr: 0.0001\n",
      "Final test loss: 1.1074\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "par = {'epochs': 100, #optimisation epochs\n",
    "       'order': 2, #order of derivatives\n",
    "       'hidden_channels': 16, #number of internal dimensions in MLP\n",
    "       'out_channels': 3,\n",
    "       'inner_product_features': True,\n",
    "      }\n",
    "\n",
    "model = net(data, **par)\n",
    "model.run_training(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818b71e",
   "metadata": {},
   "source": [
    "# Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f67159d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed umap embedding on embedded results.\n",
      "Performed MDS embedding on embedded results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = model.evaluate(data)\n",
    "n_clusters=20\n",
    "data = postprocessing(data, n_clusters=n_clusters)\n",
    "\n",
    "emb_MDS, _ = geometry.embed(data.dist, embed_typ = 'MDS')\n",
    "plotting.embedding(emb_MDS, beta1, s=30, alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314fb06",
   "metadata": {},
   "source": [
    "# Distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12592529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f87c3f165e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWU0lEQVR4nO3dfYxVhZ3/8S8zwAzQARUWFtYRoW0WBI08pSugbaNL4lNqtrHVVWu0NRJRQbJGqbb9aQuz9sGwqxUzpDG2BuWP1kiT2kpsBK1SEfFh2wbSuitTqaG67gyIjjJz949d57f0FDoX+HLuHV8vc//w5N6cT67DvD1zh3sHVSqVSgDAEdZQ9gAABiaBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBSDj/YJe3t7Y+fOndHS0hKDBg062qcH4DBUKpXYvXt3TJgwIRoaDn6NctQDs3PnzmhtbT3apwXgCOro6Ijjjz/+oPc56oFpaWmJiIj5cU4MjiFH+/QH9Mo/zyl7QsFH/qP2foL5zl/X3jsLNX50d9kTCj425s2yJxQs/ZvHyp5QMKe5sewJBXt63y17QkFDDb2asXtPb0yZvbPve/nBHPXAfPBjscExJAYPqp3ANDQ3lz2hoLGpdr6oPtDQXIOBGf5+2RMKhowYWvaEghEttff1NLK59jY19NbgphoKzAf68xJH7a0GYEAQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkOKTD33HNPTJo0KZqbm2PWrFnx5JNPHuldANS5qgOzdu3aWLJkSdxyyy2xdevWOP300+Pss8+OHTt2ZOwDoE5VHZg777wzvvjFL8aXvvSlmDp1aqxcuTJaW1tj1apVGfsAqFNVBea9996LLVu2xIIFC/Y7vmDBgnj66af/7GO6u7ujq6trvxsAA19VgXnjjTeip6cnxo0bt9/xcePGxeuvv/5nH9PW1hajRo3qu/k0S4APh0N6kf9PP2imUqkc8MNnli1bFp2dnX23jo6OQzklAHWmqk+0HDNmTDQ2NhauVnbt2lW4qvlAU1NTNDU1HfpCAOpSVVcwQ4cOjVmzZsX69ev3O75+/fqYO3fuER0GQH2r6gomImLp0qVx2WWXxezZs+O0006L9vb22LFjRyxcuDBjHwB1qurAfP7zn48333wzbr/99vjDH/4Q06dPj5/85CcxceLEjH0A1KmqAxMRcc0118Q111xzpLcAMIB4LzIAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFIf0XmRHwiv/PCcampvLOn3Bx27YVPaEgq5//LuyJxQMfufPf7Bcmd79r5FlTyh48aPDyp5QsLrpk2VPKOga88uyJxTMbX637AkFwxuGlj2hz76G3n7f1xUMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASDF4LJO/JH/aIjGptrpW9c//l3ZEwpGrtlU9oSCvf/wibInFPQMaSx7QsGg92rna/sDv3/7mLInFGxrmVD2hIK9lTfLnlBw4uDa2bSnu7ff9629PwUADAgCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApKgqMG1tbTFnzpxoaWmJsWPHxgUXXBDbtm3L2gZAHasqMBs2bIhFixbFpk2bYv369bFv375YsGBBvP3221n7AKhTVX3g2E9/+tP9/v2+++6LsWPHxpYtW+KMM844osMAqG+H9YmWnZ2dERFx3HHHHfA+3d3d0d3d3ffvXV1dh3NKAOrEIb/IX6lUYunSpTF//vyYPn36Ae/X1tYWo0aN6ru1trYe6ikBqCOHHJhrr702XnrppXjwwQcPer9ly5ZFZ2dn362jo+NQTwlAHTmkH5Fdd911sW7duti4cWMcf/zxB71vU1NTNDU1HdI4AOpXVYGpVCpx3XXXxcMPPxxPPPFETJo0KWsXAHWuqsAsWrQo1qxZE4888ki0tLTE66+/HhERo0aNimHDhqUMBKA+VfUazKpVq6KzszM+9alPxfjx4/tua9euzdoHQJ2q+kdkANAf3osMgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIMVhfWTy4XjnryvR0Fw77202+J1BZU8o2PsPnyh7QsHwH/2y7AkFu6+fW/aEgmHj95Q9oaC7p7Q/7gc0c9i/lz2h4LV9x5Y9oeDkoUPKntCna2hvv+/rCgaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkGJwWSdu/OjuaBz+flmnL3j3v0aWPaGgZ0hj2RMKdl8/t+wJBeP+9emyJxR0tNTe87RjwkfKnlDwL8P/vuwJBccO3Vv2hIIRDVvLntBn7zs9/b6vKxgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQ4rAC09bWFoMGDYolS5YcoTkADBSHHJjNmzdHe3t7nHLKKUdyDwADxCEFZs+ePXHJJZfE6tWr49hjjz3SmwAYAA4pMIsWLYpzzz03zjrrrL943+7u7ujq6trvBsDAV/VHJj/00EPx/PPPx+bNm/t1/7a2trjtttuqHgZAfavqCqajoyMWL14cDzzwQDQ3N/frMcuWLYvOzs6+W0dHxyENBaC+VHUFs2XLlti1a1fMmjWr71hPT09s3Lgx7r777uju7o7Gxsb9HtPU1BRNTU1HZi0AdaOqwJx55pnx8ssv73fsiiuuiClTpsRNN91UiAsAH15VBaalpSWmT5++37ERI0bE6NGjC8cB+HDzN/kBSFH1b5H9qSeeeOIIzABgoHEFA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJDisN+L7FB9bMybMWTE0LJOX/DiR4eVPaFg0Hu11/9h4/eUPaGgo2Vu2RMKWpc/XfaEgp3/VHvP07/94W/LnlDwTuv7ZU8oeGzwtLIn9Ol9592I+H/9um/tfQcDYEAQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUg8s68dK/eSxGtNRO31Y3fbLsCQW/f/uYsicUdPeU9iVzQDsmfKTsCQU7/2lu2RMKJnz76bInFLx51WllTygY2jmk7AkFuyf3lj3h/3u3/98Dauc7PAADisAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApqg7Ma6+9FpdeemmMHj06hg8fHqeeemps2bIlYxsAdayqD/d46623Yt68efHpT386Hn300Rg7dmz87ne/i2OOOSZpHgD1qqrA3HHHHdHa2hr33Xdf37ETTzzxSG8CYACo6kdk69ati9mzZ8eFF14YY8eOjRkzZsTq1asP+pju7u7o6ura7wbAwFdVYF555ZVYtWpVfPzjH4+f/exnsXDhwrj++uvj+9///gEf09bWFqNGjeq7tba2HvZoAGpfVYHp7e2NmTNnxooVK2LGjBlx9dVXx1VXXRWrVq064GOWLVsWnZ2dfbeOjo7DHg1A7asqMOPHj4+TTjppv2NTp06NHTt2HPAxTU1NMXLkyP1uAAx8VQVm3rx5sW3btv2Obd++PSZOnHhERwFQ/6oKzA033BCbNm2KFStWxG9/+9tYs2ZNtLe3x6JFi7L2AVCnqgrMnDlz4uGHH44HH3wwpk+fHl//+tdj5cqVcckll2TtA6BOVfX3YCIizjvvvDjvvPMytgAwgHgvMgBSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUVb8X2ZEyp7kxRjbXTt+6xvyy7AkF21omlD2hYOawfy97QsG/DP/7sicU/Nsf/rbsCQVvXnVa2RMKRq9+puwJBf95Re09T2O2Dip7Qp+e9wbFgT8BbH+18x0egAFFYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSDC7rxHt6342G3trp29zmd8ueULC38mbZEwpe23ds2RMKjh26t+wJBe+0vl/2hIKhnUPKnlDwn1ecVvaEguPue6bsCQV/XFg7z1NPFdWone/wAAwoAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKSoKjD79u2LW2+9NSZNmhTDhg2LyZMnx+233x69vb1Z+wCoU1V9Hswdd9wR9957b9x///0xbdq0eO655+KKK66IUaNGxeLFi7M2AlCHqgrMM888E5/5zGfi3HPPjYiIE088MR588MF47rnnUsYBUL+q+hHZ/Pnz4/HHH4/t27dHRMSLL74YTz31VJxzzjkHfEx3d3d0dXXtdwNg4KvqCuamm26Kzs7OmDJlSjQ2NkZPT08sX748Lr744gM+pq2tLW677bbDHgpAfanqCmbt2rXxwAMPxJo1a+L555+P+++/P7797W/H/ffff8DHLFu2LDo7O/tuHR0dhz0agNpX1RXMjTfeGDfffHNcdNFFERFx8sknx6uvvhptbW1x+eWX/9nHNDU1RVNT0+EvBaCuVHUFs3fv3mho2P8hjY2Nfk0ZgIKqrmDOP//8WL58eZxwwgkxbdq02Lp1a9x5551x5ZVXZu0DoE5VFZi77rorvvKVr8Q111wTu3btigkTJsTVV18dX/3qV7P2AVCnqgpMS0tLrFy5MlauXJk0B4CBwnuRAZBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKSo6r3IjqSG//2nVgxvGFr2hIITB79Z9oSCk4cOKXtCwYiGrWVPKHhs8LSyJxTsnlx7H6sxZuugsicU/HHhaWVPKPire58pe0KffZX3+33f2vkOD8CAIjAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSDD7aJ6xUKhERsXtP79E+9UHta6itPRERe7prb1PX0NrbtPednrInFPS+827ZE4rePep/3P+invcGlT2hoKf2nqbYV3m/7Al99sX/bPnge/nBDKr0515H0O9///tobW09mqcE4Ajr6OiI448//qD3OeqB6e3tjZ07d0ZLS0sMGnTo//fS1dUVra2t0dHRESNHjjyCCwcWz1P/eJ76x/PUPwP5eapUKrF79+6YMGFCNDQc/FWWo34x2NDQ8BerV42RI0cOuP+AGTxP/eN56h/PU/8M1Odp1KhR/bqfF/kBSCEwAKSo28A0NTXF1772tWhqaip7Sk3zPPWP56l/PE/943n6H0f9RX4APhzq9goGgNomMACkEBgAUggMACnqNjD33HNPTJo0KZqbm2PWrFnx5JNPlj2pprS1tcWcOXOipaUlxo4dGxdccEFs27at7Fk1ra2tLQYNGhRLliwpe0rNee211+LSSy+N0aNHx/Dhw+PUU0+NLVu2lD2rpuzbty9uvfXWmDRpUgwbNiwmT54ct99+e/T21t779x0tdRmYtWvXxpIlS+KWW26JrVu3xumnnx5nn3127Nixo+xpNWPDhg2xaNGi2LRpU6xfvz727dsXCxYsiLfffrvsaTVp8+bN0d7eHqecckrZU2rOW2+9FfPmzYshQ4bEo48+Gr/+9a/jO9/5ThxzzDFlT6spd9xxR9x7771x9913x29+85v45je/Gd/61rfirrvuKntaaery15Q/8YlPxMyZM2PVqlV9x6ZOnRoXXHBBtLW1lbisdv3xj3+MsWPHxoYNG+KMM84oe05N2bNnT8ycOTPuueee+MY3vhGnnnpqrFy5suxZNePmm2+OX/ziF35K8Becd955MW7cuPje977Xd+yzn/1sDB8+PH7wgx+UuKw8dXcF895778WWLVtiwYIF+x1fsGBBPP300yWtqn2dnZ0REXHccceVvKT2LFq0KM4999w466yzyp5Sk9atWxezZ8+OCy+8MMaOHRszZsyI1atXlz2r5syfPz8ef/zx2L59e0REvPjii/HUU0/FOeecU/Ky8tTgJx8c3BtvvBE9PT0xbty4/Y6PGzcuXn/99ZJW1bZKpRJLly6N+fPnx/Tp08ueU1MeeuiheP7552Pz5s1lT6lZr7zySqxatSqWLl0aX/7yl+PZZ5+N66+/PpqamuILX/hC2fNqxk033RSdnZ0xZcqUaGxsjJ6enli+fHlcfPHFZU8rTd0F5gN/+lb/lUrlsN7+fyC79tpr46WXXoqnnnqq7Ck1paOjIxYvXhyPPfZYNDc3lz2nZvX29sbs2bNjxYoVERExY8aM+NWvfhWrVq0SmP9j7dq18cADD8SaNWti2rRp8cILL8SSJUtiwoQJcfnll5c9rxR1F5gxY8ZEY2Nj4Wpl165dhasaIq677rpYt25dbNy48Yh+TMJAsGXLlti1a1fMmjWr71hPT09s3Lgx7r777uju7o7GxsYSF9aG8ePHx0knnbTfsalTp8YPf/jDkhbVphtvvDFuvvnmuOiiiyIi4uSTT45XX3012traPrSBqbvXYIYOHRqzZs2K9evX73d8/fr1MXfu3JJW1Z5KpRLXXntt/OhHP4qf//znMWnSpLIn1ZwzzzwzXn755XjhhRf6brNnz45LLrkkXnjhBXH5X/PmzSv8ivv27dtj4sSJJS2qTXv37i18AFdjY+OH+teU6+4KJiJi6dKlcdlll8Xs2bPjtNNOi/b29tixY0csXLiw7Gk1Y9GiRbFmzZp45JFHoqWlpe+Kb9SoUTFs2LCS19WGlpaWwmtSI0aMiNGjR3ut6v+44YYbYu7cubFixYr43Oc+F88++2y0t7dHe3t72dNqyvnnnx/Lly+PE044IaZNmxZbt26NO++8M6688sqyp5WnUqe++93vViZOnFgZOnRoZebMmZUNGzaUPammRMSfvd13331lT6tpn/zkJyuLFy8ue0bN+fGPf1yZPn16pampqTJlypRKe3t72ZNqTldXV2Xx4sWVE044odLc3FyZPHly5ZZbbql0d3eXPa00dfn3YACofXX3GgwA9UFgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFL8N2nzyv7FbxyCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce2f03",
   "metadata": {},
   "source": [
    "# Cluster and visualise embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [r'$\\beta$ = {:0.2f}'.format(b) for b in beta1]\n",
    "plotting.embedding(data.emb_2d, data.y.numpy(), titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attractors(data, (4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83dd7a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_clusters=[2,4,6,8]\n",
    "fig, ax = plt.subplots(len(n_clusters),4, figsize=(10,10))\n",
    "slices=data._slice_dict['x']\n",
    "\n",
    "def plot_embedding(data, ax, slices, i, n_clusters=2):\n",
    "    s = range(slices[i], slices[i+1])\n",
    "    clusters = geometry.cluster(data.emb_2d, cluster_typ='kmeans', n_clusters=n_clusters, seed=0)\n",
    "    plotting.embedding(data.emb_2d[s], clusters['labels'][s], ax=ax[0])\n",
    "    plot_phase_portrait(data.pos[s], data.x[s], ax[1], node_feature=clusters['labels'][s])\n",
    "\n",
    "snapshot=4\n",
    "for i, n in enumerate(n_clusters):\n",
    "    plot_embedding(data, ax[:,:2][i], slices, snapshot, n_clusters=n)\n",
    "    \n",
    "snapshot=5\n",
    "for i, n in enumerate(n_clusters):\n",
    "    plot_embedding(data, ax[:,2:][i], slices, snapshot, n_clusters=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59cd5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
